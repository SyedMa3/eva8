{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNqi9ycz6f95GfNIAdBByiW"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "0E6xZpTd1O01"
      },
      "outputs": [],
      "source": [
        "#importing necessary packages\n",
        "import torch\n",
        "import numpy as np\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "import torch.nn.functional as F\n",
        "import torch.nn as nn\n",
        "from torch.utils.data import Dataset\n",
        "import torch.optim as optim"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class AddDataset(Dataset):\n",
        "  \"\"\"\n",
        "    The dataset will return a tuple ((image, label), random number)\n",
        "  \"\"\"\n",
        "  def __init__(self, mnist_set):\n",
        "    self.data = mnist_set\n",
        "\n",
        "  def __getitem__(self, index):\n",
        "    r = self.data[index]\n",
        "    image, label = r\n",
        "    n = np.random.randint(10) #function used to create a random integer in [0,9]\n",
        "\n",
        "    return (image, label) , n\n",
        "\n",
        "  def __len__(self):\n",
        "    return len(self.data)\n"
      ],
      "metadata": {
        "id": "uxrG2-na1sgQ"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class Network(nn.Module):\n",
        "  def __init__(self):\n",
        "    super().__init__()\n",
        "\n",
        "    self.conv1 = nn.Conv2d(in_channels=1, out_channels=6, kernel_size=5)\n",
        "    self.conv2 = nn.Conv2d(in_channels=6, out_channels=12, kernel_size=5)\n",
        "    self.fc1 = nn.Linear(in_features=12*4*4, out_features=120)\n",
        "    self.fc2 = nn.Linear(in_features=120, out_features=60)\n",
        "    self.fc3 = nn.Linear(in_features=60, out_features=10)\n",
        "\n",
        "    self.fc4 = nn.Linear(in_features=2, out_features=30)\n",
        "    self.fc5 = nn.Linear(in_features=30, out_features=120)\n",
        "    self.out = nn.Linear(in_features=120, out_features=19)\n",
        "\n",
        "  def forward(self, t, t2):\n",
        "\n",
        "    x = t\n",
        "\n",
        "    # MNIST block starts\n",
        "    x = self.conv1(x)\n",
        "    x = F.relu(x)\n",
        "    x = F.max_pool2d(x, kernel_size=2, stride=2)\n",
        "\n",
        "    x = self.conv2(x)\n",
        "    x = F.relu(x)\n",
        "    x = F.max_pool2d(x, kernel_size=2, stride=2)\n",
        "    \n",
        "    x = x.reshape(-1, 12*4*4)\n",
        "\n",
        "    x = self.fc1(x)\n",
        "    x = F.relu(x)\n",
        "\n",
        "    x = self.fc2(x)\n",
        "    x = F.relu(x)\n",
        "\n",
        "    x = self.fc3(x)\n",
        "\n",
        "    y = x\n",
        "    #MNIST block ends\n",
        "\n",
        "    x = F.softmax(x, dim=1)\n",
        "\n",
        "    x = x.argmax(dim=1) #converting to prediction integer to use in sum block\n",
        "\n",
        "    t3 = torch.stack((x, t2), dim = 1)\n",
        "    t3 = t3.float()\n",
        "    # the input vector for the sum block will be tuple of (predicted label, random number)\n",
        "    # i.e we are combining the first input and the second input here\n",
        "\n",
        "    # sum predictor block starts\n",
        "    t3 = self.fc4(t3)\n",
        "    t3 = F.relu(t3)\n",
        "\n",
        "    t3 = self.fc5(t3)\n",
        "    t3 = F.relu(t3)\n",
        "\n",
        "    t3 = self.out(t3)\n",
        "    # sum predictor block ends\n",
        "\n",
        "    return y, t3 #returning the prediction tensors for MNIST and sum respectively"
      ],
      "metadata": {
        "id": "c0t7Bqct6bEy"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_num_correct(preds, labels):\n",
        "  return preds.argmax(dim=1).eq(labels).sum().item()"
      ],
      "metadata": {
        "id": "--5WlW6wSyRb"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "network = Network()\n",
        "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu') #setting device as GPU if available\n",
        "\n",
        "network.to(device) #moving the neural network to device(GPU if available)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "04Fvpl29TeWU",
        "outputId": "09cf24a8-ab8e-4488-f87f-8e4ebc07aaf5"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Network(\n",
              "  (conv1): Conv2d(1, 6, kernel_size=(5, 5), stride=(1, 1))\n",
              "  (conv2): Conv2d(6, 12, kernel_size=(5, 5), stride=(1, 1))\n",
              "  (fc1): Linear(in_features=192, out_features=120, bias=True)\n",
              "  (fc2): Linear(in_features=120, out_features=60, bias=True)\n",
              "  (fc3): Linear(in_features=60, out_features=10, bias=True)\n",
              "  (fc4): Linear(in_features=2, out_features=30, bias=True)\n",
              "  (fc5): Linear(in_features=30, out_features=120, bias=True)\n",
              "  (out): Linear(in_features=120, out_features=19, bias=True)\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "mnist_set = torchvision.datasets.MNIST(\n",
        "    root='./data',\n",
        "    train=True,\n",
        "    download=True,\n",
        "    transform=transforms.Compose([\n",
        "        transforms.ToTensor()\n",
        "    ])\n",
        ")\n",
        "\n",
        "train_set = AddDataset(mnist_set) #converting the MNIST dataset into our custom dataset"
      ],
      "metadata": {
        "id": "rj03LS8_6K5E"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_loader = torch.utils.data.DataLoader(\n",
        "    train_set,\n",
        "    batch_size=100,\n",
        "    shuffle=True\n",
        ") #initialising a dataLoader with batch_size = 100\n",
        "\n",
        "optimiser = optim.Adam(network.parameters(), lr=0.01)\n",
        "\n",
        "for epoch in range(15):\n",
        "\n",
        "  total_loss = 0\n",
        "  total_image_correct = 0\n",
        "  total_sum_correct = 0\n",
        "\n",
        "\n",
        "  for batch in train_loader:\n",
        "    (images, labels), ns = batch\n",
        "    \n",
        "    images = images.to(device)\n",
        "    labels = labels.to(device)\n",
        "    ns = ns.to(device)\n",
        "\n",
        "\n",
        "    preds = network(images, ns)\n",
        "\n",
        "    #different losses for the two predictions\n",
        "    image_loss = F.cross_entropy(preds[0], labels)\n",
        "    add_loss = F.cross_entropy(preds[1], labels+ns)\n",
        "\n",
        "    optimiser.zero_grad()\n",
        "    #different backward props since they have different tensors and different losses\n",
        "    image_loss.backward()\n",
        "    add_loss.backward()\n",
        "\n",
        "    optimiser.step()\n",
        "\n",
        "    total_loss += (image_loss + add_loss).item()\n",
        "    total_image_correct += get_num_correct(preds[0], labels)\n",
        "    total_sum_correct += get_num_correct(preds[1], labels+ns)\n",
        "\n",
        "  print(\"epoch\", epoch)\n",
        "  print(\n",
        "      \"image loss:\", total_loss,\n",
        "      \"add loss:\", total_loss,\n",
        "      \"image_accuracy:\", (total_image_correct/60000),\n",
        "      \"add_accuracy:\", (total_sum_correct/60000)\n",
        "  )\n"
      ],
      "metadata": {
        "id": "sV4l3w-06T9A",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6c99130e-c980-4a4f-fd4a-36492e371a06"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch 0\n",
            "image loss: 827.0129678547382 add loss: 827.0129678547382 image_accuracy: 0.9443666666666667 add_accuracy: 0.6745\n",
            "epoch 1\n",
            "image loss: 383.8723166882992 add loss: 383.8723166882992 image_accuracy: 0.9779833333333333 add_accuracy: 0.9458\n",
            "epoch 2\n",
            "image loss: 244.88867956399918 add loss: 244.88867956399918 image_accuracy: 0.9804333333333334 add_accuracy: 0.9771833333333333\n",
            "epoch 3\n",
            "image loss: 180.79763338714838 add loss: 180.79763338714838 image_accuracy: 0.9830833333333333 add_accuracy: 0.9814333333333334\n",
            "epoch 4\n",
            "image loss: 159.52213974110782 add loss: 159.52213974110782 image_accuracy: 0.9838666666666667 add_accuracy: 0.9795333333333334\n",
            "epoch 5\n",
            "image loss: 136.27398498170078 add loss: 136.27398498170078 image_accuracy: 0.9851 add_accuracy: 0.9821333333333333\n",
            "epoch 6\n",
            "image loss: 135.65634261630476 add loss: 135.65634261630476 image_accuracy: 0.9851166666666666 add_accuracy: 0.9828333333333333\n",
            "epoch 7\n",
            "image loss: 124.36413899995387 add loss: 124.36413899995387 image_accuracy: 0.9861 add_accuracy: 0.9854\n",
            "epoch 8\n",
            "image loss: 128.808935996145 add loss: 128.808935996145 image_accuracy: 0.9859 add_accuracy: 0.9829333333333333\n",
            "epoch 9\n",
            "image loss: 117.72591435536742 add loss: 117.72591435536742 image_accuracy: 0.9865 add_accuracy: 0.9860833333333333\n",
            "epoch 10\n",
            "image loss: 116.44235399365425 add loss: 116.44235399365425 image_accuracy: 0.98675 add_accuracy: 0.9857666666666667\n",
            "epoch 11\n",
            "image loss: 100.41467364691198 add loss: 100.41467364691198 image_accuracy: 0.98875 add_accuracy: 0.9877166666666667\n",
            "epoch 12\n",
            "image loss: 106.67389107029885 add loss: 106.67389107029885 image_accuracy: 0.98815 add_accuracy: 0.9868333333333333\n",
            "epoch 13\n",
            "image loss: 114.74705079384148 add loss: 114.74705079384148 image_accuracy: 0.9881333333333333 add_accuracy: 0.9798666666666667\n",
            "epoch 14\n",
            "image loss: 103.35864684358239 add loss: 103.35864684358239 image_accuracy: 0.988 add_accuracy: 0.9877833333333333\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "torch.set_grad_enabled(False)\n",
        "sample = train_set[10] \n",
        "(image, label), n = sample\n",
        "# image.shape, image.unsqueeze(0).shape\n",
        "\n",
        "prred = network(image.to(device), torch.tensor([n]).to(device))\n",
        "torch.set_grad_enabled(True)\n",
        "print(prred, \"tt:\", label, n)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nYpRn6RZfC_W",
        "outputId": "89148062-f38e-421a-bead-48efa8da9372"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(tensor([[-18.7109,  -3.2683,  -8.1701,  25.6209, -15.6780,  13.8173, -12.4034,\n",
            "           1.3868,   0.9079,  11.7303]], device='cuda:0'), tensor([[ -20.6820,  -12.2311,   -9.4469,   -9.2068,   -6.7497,   -6.5078,\n",
            "           -4.6843,    1.2212,   -1.9230,   -6.0582,   -2.5299,   -4.9681,\n",
            "           -2.9078,   -3.8296,   -7.3303,  -10.1213,  -10.1486,  -30.7801,\n",
            "         -104.2772]], device='cuda:0')) tt: 3 4\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "UVFmQRxIZBo_"
      },
      "execution_count": 8,
      "outputs": []
    }
  ]
}